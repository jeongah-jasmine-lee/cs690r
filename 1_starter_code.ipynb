{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "This is starter code designed to provide the basic instructions on how to use the dataset and models.\n",
    "Feel free to create your code from scratch or modify this as you wish.\n",
    "\n",
    "Submit a compressed archive containing all source code files.\n",
    "Ensure the code is well-documented, with comments explaining key functions and logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** To be able to reconstruct the upper limbs poses (MoCap) based on inertial data (IMU)\n",
    "\n",
    "**Motivation:** MoCap data collection is expensive and requires very controlled environments. On the other hand, IMU data collection is cheaper and portable. Reconstructing MoCap from IMU would offer a cheap alternative to predict upper-limb poses and improve downstream HAR tasks.\n",
    "\n",
    "**Problem formulation:** To create a system that receives IMU data in form of local acceleration and gyroscope and predicts relative coordinates of shoulder, elbow, wrist and thumb with respect to the subject's center of gravity\n",
    "- Let $a_l, a_r, \\omega_l, \\omega_r \\in R^{T \\times 3}$ be the arrays of local left/right acceleration and gyroscope\n",
    "- Let $p_{ls}, p_{le}, p_{lw}, p_{lt}, p_{rs}, p_{re}, p_{rw}, p_{rt} \\in R^{T \\times 3}$ be the arrays of relative positions left/right of shoulder, elbow, wrist and thumb with respect to the anatomical frame of coordinates (see next section for more info)\n",
    "- Develop a system $f(a_l, a_r, \\omega_l, \\omega_r) \\rightarrow \\hat p_{ls}, \\hat p_{le}, \\hat p_{lw}, \\hat p_{lt}, \\hat p_{rs}, \\hat p_{re}, \\hat p_{rw}, \\hat p_{rt}$ such that $\\hat p_i$ is a good estimator of $p_i$\n",
    "\n",
    "**Considerations:**\n",
    "- What is a good estimator? A typical approach is to say $\\hat p_i$ is a good esimator of $p_i$ if $||\\hat p_i - p_i||_2 \\approx 0$. However, it is encouraged to explore additional ways to measure this, such as, preservation of bone lengths (i.e., $||\\hat p_{ls}[t] - \\hat p_{le}[t]||_2$ is relatively constant $\\forall t$), feasibility of joint angles (i.e., $\\textrm{angle} (\\hat p_{ls}[t], \\hat p_{le}[t], \\hat p_{lw}[t]) < \\pi$), etc. **Be creative with this part.**\n",
    "- What model to use? This is **the core of the project**, so make sure to develop a strong (not necessarily complex) model. Its performance will highly depend on what you defined in the previous consideration.\n",
    "- How to treat temporal dimension? In the example below, different activities have different lengths. Therefore, in order to train each batch pads the shorter sequences to the longest for that batch. Feel free to use other approaches if you wish.\n",
    "- Is subject distinction important? **Yes**, the example below provides a split using LOSO without CV, but you should use LOSO-CV. You can also try LOAO-CV (leave one activity out with cross validation).\n",
    "- Use different data? Feel free to use other data, as long as you have pairs of MoCap/IMU. The data provided comes from AMASS [1], a MoCap dataset, from which IMU was obtained synthetically using VirtualIMU [2].\n",
    "\n",
    "\n",
    "[1] Mahmood, Naureen, et al. \"AMASS: Archive of motion capture as surface shapes.\" *Proceedings of the IEEE/CVF international conference on computer vision.* 2019.\n",
    "\n",
    "[2] Gavier, Ignacio, et al. \"VirtualIMU: Generating Virtual Wearable Inertial Data from Video for Deep Learning Applications.\" *2023 IEEE 19th International Conference on Body Sensor Networks (BSN).* IEEE, 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Location:** Data is located in folder `./data/`\n",
    "\n",
    "**Name convention:** Each file has a name with the structure `[activity]_s[subject_id]_[length].npz`, where `activity` is the activity performed by a subject, `subject_id` is a number in `(1-10)`, and `length` is the length of the activity measured in frames\n",
    "\n",
    "**Content:** Each file contains the following arrays\n",
    "- `time` of shape `(length,)`: array containing time information\n",
    "- `leftShoulderPosRel` of shape `(length, 3)`: XYZ array containing left shoulder position relative to the subject's center of gravity\n",
    "- `rightShoulderPosRel` of shape `(length, 3)`: XYZ array containing right shoulder position relative to the subject's center of gravity\n",
    "- `leftElbowPosRel` of shape `(length, 3)`: XYZ array containing left elbow position relative to the subject's center of gravity\n",
    "- `rightElbowPosRel` of shape `(length, 3)`: XYZ array containing right elbow position relative to the subject's center of gravity\n",
    "- `leftWristPosRel` of shape `(length, 3)`: XYZ array containing left wrist position relative to the subject's center of gravity\n",
    "- `rightWristPosRel` of shape `(length, 3)`: XYZ array containing right wrist position relative to the subject's center of gravity\n",
    "- `leftFingerPosRel` of shape `(length, 3)`: XYZ array containing left thumb position relative to the subject's center of gravity\n",
    "- `rightFingerPosRel` of shape `(length, 3)`: XYZ array containing right thumb position relative to the subject's center of gravity\n",
    "- `accelerationLeftLoc` of shape `(length, 3)`: XYZ array containing left forearm local acceleration \n",
    "- `accelerationRightLoc` of shape `(length, 3)`: XYZ array containing right forearm local acceleration \n",
    "- `gyroLeftLoc` of shape `(length, 3)`: XYZ array containing left forearm local gyroscope \n",
    "- `gyroRightLoc` of shape `(length, 3)`: XYZ array containing right forearm local gyroscope \n",
    "\n",
    "**Axes convention (MoCap):** The data files assume the following directions for MoCap\n",
    "- X: lateral direction, left to right is positive\n",
    "- Y: frontal direction, back to front is positive\n",
    "- Z: vertical direction, down to up is positive\n",
    "\n",
    "**Axes convention (IMU):** The data files assume the following directions for IMU\n",
    "- X: forearm direction, elbow to wrist is positive\n",
    "- Y: ulnar-radial direction, in left sensor radial to ulnar is positive, in right sensor ulnar to radial is positive\n",
    "- Z: palmar-dorsal direction, palmar to dorsal is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anm\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob('./data/*.npz')\n",
    "assert len(filenames) > 0, 'No data files found in ./data/'\n",
    "\n",
    "filename = filenames[0]\n",
    "data = np.load(filename)\n",
    "print('Data containing:')\n",
    "[print(f'Array {f} of shape {data[f].shape}') for f in data.files];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract MoCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMoCap(data):\n",
    "    time = data['time'] # (T,)\n",
    "    torso = np.stack([np.zeros_like(data['leftShoulderPosRel']),\n",
    "                      data['leftShoulderPosRel'],\n",
    "                      data['rightShoulderPosRel'],\n",
    "                      np.zeros_like(data['rightShoulderPosRel'])], axis=1) # (T, 4, 3)\n",
    "    left_arm = np.stack([data['leftShoulderPosRel'],\n",
    "                         data['leftElbowPosRel'],\n",
    "                         data['leftWristPosRel'],\n",
    "                         data['leftFingerPosRel']], axis=1) # (T, 4, 3)\n",
    "    right_arm = np.stack([data['rightShoulderPosRel'],\n",
    "                          data['rightElbowPosRel'],\n",
    "                          data['rightWristPosRel'],\n",
    "                          data['rightFingerPosRel']], axis=1) # (T, 4, 3)\n",
    "\n",
    "    return time, torso, left_arm, right_arm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize MoCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(16,14))\n",
    "\n",
    "t = 0 # Select frame to observe\n",
    "time, torso, left_arm, right_arm = extractMoCap(data)\n",
    "\n",
    "[ax[i,j].set_xlim(-1,1) for i in range(2) for j in range(2)]\n",
    "[ax[i,j].set_ylim(-1,1) for i in range(2) for j in range(2)]\n",
    "\n",
    "ax[0,0].set_title('View from behind')\n",
    "ax[0,0].set_xlabel('Lateral')\n",
    "ax[0,0].set_ylabel('Vertical')\n",
    "t_00, = ax[0,0].plot(torso[t,:,0], torso[t,:,2], '-o', label='Torso')\n",
    "l_00, = ax[0,0].plot(left_arm[t,:,0], left_arm[t,:,2], '-o', label='Left Arm')\n",
    "r_00, = ax[0,0].plot(right_arm[t,:,0], right_arm[t,:,2], '-o', label='Right Arm')\n",
    "ax[0,0].legend(loc='upper left')\n",
    "\n",
    "ax[0,1].set_title('View from right')\n",
    "ax[0,1].set_xlabel('Frontal')\n",
    "ax[0,1].set_ylabel('Vertical')\n",
    "t_01, = ax[0,1].plot(torso[t,:,1], torso[t,:,2], '-o', label='Torso')\n",
    "l_01, = ax[0,1].plot(left_arm[t,:,1], left_arm[t,:,2], '-o', label='Left Arm')\n",
    "r_01, = ax[0,1].plot(right_arm[t,:,1], right_arm[t,:,2], '-o', label='Right Arm')\n",
    "ax[0,1].legend(loc='upper left')\n",
    "\n",
    "ax[1,0].set_title('View from top')\n",
    "ax[1,0].set_xlabel('Lateral')\n",
    "ax[1,0].set_ylabel('Frontal')\n",
    "t_10, = ax[1,0].plot(torso[t,:,0], torso[t,:,1], '-o', label='Torso')\n",
    "l_10, = ax[1,0].plot(left_arm[t,:,0], left_arm[t,:,1], '-o', label='Left Arm')\n",
    "r_10, = ax[1,0].plot(right_arm[t,:,0], right_arm[t,:,1], '-o', label='Right Arm')\n",
    "ax[1,0].legend(loc='upper left')\n",
    "\n",
    "ax[1,1].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractIMU(data):\n",
    "    time = data['time'] # (T,)\n",
    "    left_acc = data['accelerationLeftLoc'] # (T, 3)\n",
    "    right_acc = data['accelerationRightLoc'] # (T, 3)\n",
    "    left_gyro = data['gyroLeftLoc'] # (T, 3)\n",
    "    right_gyro = data['gyroRightLoc'] # (T, 3)\n",
    "\n",
    "    return time, left_acc, right_acc, left_gyro, right_gyro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(16,6), sharex=True, sharey='row')\n",
    "\n",
    "time, left_acc, right_acc, left_gyro, right_gyro = extractIMU(data)\n",
    "\n",
    "ax[0,0].set_ylim(-20,20)\n",
    "ax[1,0].set_ylim(-np.pi,np.pi)\n",
    "\n",
    "ax[0,0].set_title('Left sensor acceleration')\n",
    "ax[0,0].set_ylabel('Acceleration (m/s^2)')\n",
    "ax[0,0].plot(time, left_acc, label=['x', 'y', 'z'])\n",
    "ax[0,0].legend(loc='upper left')\n",
    "\n",
    "ax[0,1].set_title('Right sensor acceleration')\n",
    "ax[0,1].plot(time, right_acc, label=['x', 'y', 'z'])\n",
    "ax[0,1].legend(loc='upper left')\n",
    "\n",
    "ax[1,0].set_title('Left sensor gyroscope')\n",
    "ax[1,0].set_xlabel('Time (s)')\n",
    "ax[1,0].set_ylabel('Gyroscope (rad/s)')\n",
    "ax[1,0].plot(time, left_gyro, label=['x', 'y', 'z'])\n",
    "ax[1,0].legend(loc='upper left')\n",
    "\n",
    "ax[1,1].set_title('Right sensor gyroscope')\n",
    "ax[1,1].set_xlabel('Time (s)')\n",
    "ax[1,1].plot(time, right_gyro, label=['x', 'y', 'z'])\n",
    "ax[1,1].legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, filenames):\n",
    "        self.filenames = filenames\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        data = np.load(filename)\n",
    "        time, torso, left_arm, right_arm = extractMoCap(data)\n",
    "        time, left_acc, right_acc, left_gyro, right_gyro = extractIMU(data)\n",
    "\n",
    "        mocap = np.concatenate([left_arm, right_arm], axis=1) # (T, 8, 3)\n",
    "        imu = np.stack([left_acc, right_acc, left_gyro, right_gyro], axis=1) # (T, 4, 3)\n",
    "\n",
    "        return {'time': torch.tensor(time, dtype=torch.float32),\n",
    "                'mocap': torch.tensor(mocap, dtype=torch.float32),\n",
    "                'imu': torch.tensor(imu, dtype=torch.float32)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = np.unique([f.split('_')[-2] for f in filenames])\n",
    "\n",
    "print(f'Found subjects: {subjects}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split train/test using LOSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation = np.random.permutation(len(subjects))\n",
    "train_subjects = subjects[permutation[:-1]]\n",
    "test_subjects = subjects[permutation[-1:]]\n",
    "\n",
    "print(f'Training on subjects: {train_subjects}')\n",
    "print(f'Testing on subjects: {test_subjects}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset([f for f in filenames if any(s == f.split('_')[-2] for s in train_subjects)])\n",
    "test_dataset = CustomDataset([f for f in filenames if any(s == f.split('_')[-2] for s in test_subjects)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collate function to deal with different lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    longest_sample = max(batch, key=lambda x: len(x['time']))\n",
    "    max_len = len(longest_sample['time']) # max_len\n",
    "    padded_batch = []\n",
    "\n",
    "    for sample in batch:\n",
    "        padding_len = max_len - len(sample['time'])\n",
    "        padded_sample = {}\n",
    "        padded_sample['mocap'] = torch.cat([sample['mocap'],\n",
    "                                            sample['mocap'][-1:].repeat(padding_len,1,1)]) # (max_len, 8, 3)\n",
    "        acc = torch.cat([sample['imu'][:,[0,1]],\n",
    "                         sample['imu'][-1:,[0,1]].repeat(padding_len,1,1)]) # (max_len, 2, 3)\n",
    "        gyro = torch.cat([sample['imu'][:,[2,3]],\n",
    "                          torch.zeros_like(sample['imu'][-1:,[2,3]]).repeat(padding_len,1,1)]) # (max_len, 2, 3)\n",
    "        padded_sample['imu'] = torch.cat([acc, gyro], dim=1) # (max_len, 4, 3)\n",
    "        padded_batch.append(padded_sample)\n",
    "\n",
    "    return {'time': longest_sample['time'],\n",
    "            'mocap': torch.stack([sample['mocap'] for sample in padded_batch]),\n",
    "            'imu': torch.stack([sample['imu'] for sample in padded_batch])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size=4*3, hidden_size=8*3, num_layers=2):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(2) # (N, T, 12)\n",
    "        out, _ = self.lstm(x) # (N, T, 24)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN(input_size=4*3, hidden_size=8*3, num_layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch [1/25]\n",
      "Train Step [10/122], Loss: 0.0990\n",
      "Train Step [20/122], Loss: 0.0739\n",
      "Train Step [30/122], Loss: 0.0522\n",
      "Train Step [40/122], Loss: 0.0385\n",
      "Train Step [50/122], Loss: 0.0334\n",
      "Train Step [60/122], Loss: 0.0190\n",
      "Train Step [70/122], Loss: 0.0167\n",
      "Train Step [80/122], Loss: 0.0101\n",
      "Train Step [90/122], Loss: 0.0182\n",
      "Train Step [100/122], Loss: 0.0131\n",
      "Train Step [110/122], Loss: 0.0173\n",
      "Train Step [120/122], Loss: 0.0124\n",
      "Test Step [10/12], Loss: 0.0181\n",
      "Running epoch [2/25]\n",
      "Train Step [10/122], Loss: 0.0161\n",
      "Train Step [20/122], Loss: 0.0118\n",
      "Train Step [30/122], Loss: 0.0161\n",
      "Train Step [40/122], Loss: 0.0106\n",
      "Train Step [50/122], Loss: 0.0127\n",
      "Train Step [60/122], Loss: 0.0084\n",
      "Train Step [70/122], Loss: 0.0079\n",
      "Train Step [80/122], Loss: 0.0064\n",
      "Train Step [90/122], Loss: 0.0105\n",
      "Train Step [100/122], Loss: 0.0085\n",
      "Train Step [110/122], Loss: 0.0121\n",
      "Train Step [120/122], Loss: 0.0096\n",
      "Test Step [10/12], Loss: 0.0162\n",
      "Running epoch [3/25]\n",
      "Train Step [10/122], Loss: 0.0113\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Running epoch [{epoch+1}/{num_epochs}]')\n",
    "\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        # Forward pass\n",
    "        outputs = model(batch['imu'])\n",
    "        loss = criterion(outputs.view(*batch['mocap'].shape), batch['mocap'])\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Train Step [{i+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        # Forward pass\n",
    "        outputs = model(batch['imu'])\n",
    "        loss = criterion(outputs.view(*batch['mocap'].shape), batch['mocap'])\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Test Step [{i+1}/{len(test_dataloader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './BASE_LSTM_option1_epoch_25.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
