{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment option\n",
    "\n",
    "1. Try different models: \n",
    "- LSTM/GRU Networks: The starter code already includes a simple LSTM model. This is a good starting point as temporal dependencies are important.\n",
    "- Transformer-based models: Could capture long-range dependencies better than LSTMs.\n",
    "- Graph Neural Networks (GNNs): Especially useful if you model the skeleton as a graph structure.\n",
    "\n",
    "2. Bio-mechanical Constraints\n",
    "- Loss function constraints: Add penalty terms to your loss function that increase when predictions violate biomechanical constraints.\n",
    "- Post-processing corrections: Apply corrections to predictions that violate constraints.\n",
    "- Constrained outputs: Use activation functions that limit the output range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob('../data/*.npz')\n",
    "assert len(filenames) > 0, 'No data files found in ./data/'\n",
    "\n",
    "filename = filenames[1]\n",
    "data = np.load(filename)\n",
    "print('Data containing:')\n",
    "[print(f'Array {f} of shape {data[f].shape}') for f in data.files];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = np.diff(data['time'])\n",
    "SAMPLE_RATE = 1.0 / np.mean(dt)\n",
    "print('Sample rate:', SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize MoCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(16,14))\n",
    "\n",
    "t = 0 # Select frame to observe\n",
    "time, torso, left_arm, right_arm = extractMoCap(data)\n",
    "\n",
    "[ax[i,j].set_xlim(-1,1) for i in range(2) for j in range(2)]\n",
    "[ax[i,j].set_ylim(-1,1) for i in range(2) for j in range(2)]\n",
    "\n",
    "ax[0,0].set_title('View from behind')\n",
    "ax[0,0].set_xlabel('Lateral')\n",
    "ax[0,0].set_ylabel('Vertical')\n",
    "t_00, = ax[0,0].plot(torso[t,:,0], torso[t,:,2], '-o', label='Torso')\n",
    "l_00, = ax[0,0].plot(left_arm[t,:,0], left_arm[t,:,2], '-o', label='Left Arm')\n",
    "r_00, = ax[0,0].plot(right_arm[t,:,0], right_arm[t,:,2], '-o', label='Right Arm')\n",
    "ax[0,0].legend(loc='upper left')\n",
    "\n",
    "ax[0,1].set_title('View from right')\n",
    "ax[0,1].set_xlabel('Frontal')\n",
    "ax[0,1].set_ylabel('Vertical')\n",
    "t_01, = ax[0,1].plot(torso[t,:,1], torso[t,:,2], '-o', label='Torso')\n",
    "l_01, = ax[0,1].plot(left_arm[t,:,1], left_arm[t,:,2], '-o', label='Left Arm')\n",
    "r_01, = ax[0,1].plot(right_arm[t,:,1], right_arm[t,:,2], '-o', label='Right Arm')\n",
    "ax[0,1].legend(loc='upper left')\n",
    "\n",
    "ax[1,0].set_title('View from top')\n",
    "ax[1,0].set_xlabel('Lateral')\n",
    "ax[1,0].set_ylabel('Frontal')\n",
    "t_10, = ax[1,0].plot(torso[t,:,0], torso[t,:,1], '-o', label='Torso')\n",
    "l_10, = ax[1,0].plot(left_arm[t,:,0], left_arm[t,:,1], '-o', label='Left Arm')\n",
    "r_10, = ax[1,0].plot(right_arm[t,:,0], right_arm[t,:,1], '-o', label='Right Arm')\n",
    "ax[1,0].legend(loc='upper left')\n",
    "\n",
    "ax[1,1].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(16,6), sharex=True, sharey='row')\n",
    "\n",
    "time, left_acc, right_acc, left_gyro, right_gyro = extractIMU(data)\n",
    "\n",
    "ax[0,0].set_ylim(-20,20)\n",
    "ax[1,0].set_ylim(-np.pi,np.pi)\n",
    "\n",
    "ax[0,0].set_title('Left sensor acceleration')\n",
    "ax[0,0].set_ylabel('Acceleration (m/s^2)')\n",
    "ax[0,0].plot(time, left_acc, label=['x', 'y', 'z'])\n",
    "ax[0,0].legend(loc='upper left')\n",
    "\n",
    "ax[0,1].set_title('Right sensor acceleration')\n",
    "ax[0,1].plot(time, right_acc, label=['x', 'y', 'z'])\n",
    "ax[0,1].legend(loc='upper left')\n",
    "\n",
    "ax[1,0].set_title('Left sensor gyroscope')\n",
    "ax[1,0].set_xlabel('Time (s)')\n",
    "ax[1,0].set_ylabel('Gyroscope (rad/s)')\n",
    "ax[1,0].plot(time, left_gyro, label=['x', 'y', 'z'])\n",
    "ax[1,0].legend(loc='upper left')\n",
    "\n",
    "ax[1,1].set_title('Right sensor gyroscope')\n",
    "ax[1,1].set_xlabel('Time (s)')\n",
    "ax[1,1].plot(time, right_gyro, label=['x', 'y', 'z'])\n",
    "ax[1,1].legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(16,6), sharex=True, sharey='row')\n",
    "\n",
    "left_acc_filt, left_gyro_filt = fuse_and_rotate(left_acc, left_gyro, sample_rate=SAMPLE_RATE)\n",
    "\n",
    "right_acc_filt, right_gyro_filt = fuse_and_rotate(right_acc, right_gyro, sample_rate=SAMPLE_RATE)\n",
    "\n",
    "ax[0,0].set_ylim(-20,20)\n",
    "ax[1,0].set_ylim(-np.pi,np.pi)\n",
    "\n",
    "ax[0,0].set_title('Left sensor acceleration - filtered')\n",
    "ax[0,0].set_ylabel('Acceleration (m/s^2)')\n",
    "ax[0,0].plot(time, left_acc_filt, label=['x', 'y', 'z'])\n",
    "ax[0,0].legend(loc='upper left')\n",
    "\n",
    "ax[0,1].set_title('Right sensor acceleration - filtered')\n",
    "ax[0,1].plot(time, right_acc_filt, label=['x', 'y', 'z'])\n",
    "ax[0,1].legend(loc='upper left')\n",
    "\n",
    "ax[1,0].set_title('Left sensor gyroscope - filtered')\n",
    "ax[1,0].set_xlabel('Time (s)')\n",
    "ax[1,0].set_ylabel('Gyroscope (rad/s)')\n",
    "ax[1,0].plot(time, left_gyro_filt, label=['x', 'y', 'z'])\n",
    "ax[1,0].legend(loc='upper left')\n",
    "\n",
    "ax[1,1].set_title('Right sensor gyroscope - filtered')\n",
    "ax[1,1].set_xlabel('Time (s)')\n",
    "ax[1,1].plot(time, right_gyro_filt, label=['x', 'y', 'z'])\n",
    "ax[1,1].legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.signal import welch\n",
    "\n",
    "# def plot_imu_psd(raw_imu_signals, sample_rate=60.0, sensor_label='IMU Sensor'):\n",
    "#     \"\"\"\n",
    "#     Plot Power Spectral Density (PSD) for each axis of IMU signals.\n",
    "\n",
    "#     Args:\n",
    "#         raw_imu_signals: np.ndarray of shape (T, 3), where T is timesteps and 3 axes.\n",
    "#         sample_rate: Sampling frequency in Hz.\n",
    "#         sensor_label: Label for the sensor (e.g., 'Left Accelerometer').\n",
    "#     \"\"\"\n",
    "#     # Compute PSD using Welch's method\n",
    "#     f, Pxx = welch(raw_imu_signals, fs=sample_rate, axis=0, nperseg=1024)\n",
    "\n",
    "#     # Plot each axis on the same figure\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     plt.semilogy(f, Pxx[:, 0], label='Axis X')\n",
    "#     plt.semilogy(f, Pxx[:, 1], label='Axis Y')\n",
    "#     plt.semilogy(f, Pxx[:, 2], label='Axis Z')\n",
    "    \n",
    "#     plt.title(f'Power Spectral Density - {sensor_label}')\n",
    "#     plt.xlabel('Frequency (Hz)')\n",
    "#     plt.ylabel('PSD (V^2/Hz)')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True, which='both', linestyle='--', alpha=0.5)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Example usage:\n",
    "# # Assuming left_acc, right_acc, left_gyro, right_gyro are numpy arrays (T,3)\n",
    "# # and sample_rate is defined\n",
    "# plot_imu_psd(left_acc_filt, sample_rate=60.0, sensor_label='Left Accelerometer')\n",
    "# plot_imu_psd(right_acc_filt, sample_rate=60.0, sensor_label='Right Accelerometer')\n",
    "# plot_imu_psd(left_gyro, sample_rate=60.0, sensor_label='Left Gyroscope')\n",
    "# plot_imu_psd(right_gyro, sample_rate=60.0, sensor_label='Right Gyroscope')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_imu_fft(raw_imu_signals, sample_rate=60.0, sensor_label='IMU Sensor'):\n",
    "#     \"\"\"\n",
    "#     Plot FFT magnitude spectrum for each axis of IMU signals.\n",
    "\n",
    "#     Args:\n",
    "#         raw_imu_signals: np.ndarray of shape (T, 3), where T is timesteps and 3 axes.\n",
    "#         sample_rate: Sampling frequency in Hz.\n",
    "#         sensor_label: Label for the sensor (e.g., 'Left Accelerometer').\n",
    "#     \"\"\"\n",
    "#     T = raw_imu_signals.shape[0]\n",
    "#     # Compute FFT for each axis\n",
    "#     freqs = np.fft.rfftfreq(T, d=1.0 / sample_rate)  # frequencies\n",
    "#     fft_vals = np.fft.rfft(raw_imu_signals, axis=0)   # FFT values\n",
    "\n",
    "#     axes = ['X', 'Y', 'Z']\n",
    "#     for i in range(3):\n",
    "#         magnitude = np.abs(fft_vals[:, i]) / T  # normalize\n",
    "#         plt.figure(figsize=(8, 4))\n",
    "#         plt.plot(freqs, magnitude)\n",
    "#         plt.title(f'FFT Magnitude Spectrum - {sensor_label} Axis {axes[i]}')\n",
    "#         plt.xlabel('Frequency (Hz)')\n",
    "#         plt.ylabel('Magnitude')\n",
    "#         plt.grid(True, linestyle='--', alpha=0.5)\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "\n",
    "# # Example usage with your raw data arrays:\n",
    "# plot_imu_fft(left_acc_filt,  sample_rate=60.0, sensor_label='Left Accelerometer')\n",
    "# plot_imu_fft(right_acc_filt, sample_rate=60.0, sensor_label='Right Accelerometer')\n",
    "# plot_imu_fft(left_gyro, sample_rate=60.0, sensor_label='Left Gyroscope')\n",
    "# plot_imu_fft(right_gyro, sample_rate=60.0, sensor_label='Right Gyroscope')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import *\n",
    "from losses import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = np.unique([f.split('_')[-2] for f in filenames])\n",
    "\n",
    "print(f'Found subjects: {subjects}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split train/test using LOSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # For reproducibility\n",
    "permutation = np.random.permutation(len(subjects))\n",
    "train_subjects = subjects[permutation[:-1]]\n",
    "test_subjects = subjects[permutation[-1:]]\n",
    "\n",
    "print(f'Training on subjects: {train_subjects}')\n",
    "print(f'Testing on subjects: {test_subjects}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = CustomDataset([f for f in filenames if any(s == f.split('_')[-2] for s in train_subjects)])\n",
    "# test_dataset = CustomDataset([f for f in filenames if any(s == f.split('_')[-2] for s in test_subjects)])\n",
    "\n",
    "window_size = 60\n",
    "window_shift = 15\n",
    "train_dataset = IMUDataset([f for f in filenames if any(s == f.split('_')[-2] for s in train_subjects)], \n",
    "                           filter=False, \n",
    "                           window_size=window_size, \n",
    "                           window_shift=window_shift)\n",
    "test_dataset = IMUDataset([f for f in filenames if any(s == f.split('_')[-2] for s in test_subjects)], \n",
    "                          filter=False, \n",
    "                          window_size=window_size, \n",
    "                          window_shift=window_shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collate function to deal with different lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    longest_sample = max(batch, key=lambda x: len(x['time']))\n",
    "    max_len = len(longest_sample['time']) # max_len\n",
    "    padded_batch = []\n",
    "\n",
    "    for sample in batch:\n",
    "        padding_len = max_len - len(sample['time'])\n",
    "        padded_sample = {}\n",
    "        padded_sample['mocap'] = torch.cat([sample['mocap'],\n",
    "                                            sample['mocap'][-1:].repeat(padding_len,1,1)]) # (max_len, 8, 3)\n",
    "        acc = torch.cat([sample['imu'][:,[0,1]],\n",
    "                         sample['imu'][-1:,[0,1]].repeat(padding_len,1,1)]) # (max_len, 2, 3)\n",
    "        gyro = torch.cat([sample['imu'][:,[2,3]],\n",
    "                          torch.zeros_like(sample['imu'][-1:,[2,3]]).repeat(padding_len,1,1)]) # (max_len, 2, 3)\n",
    "        padded_sample['imu'] = torch.cat([acc, gyro], dim=1) # (max_len, 4, 3)\n",
    "        padded_batch.append(padded_sample)\n",
    "\n",
    "    return {'time': longest_sample['time'],\n",
    "            'mocap': torch.stack([sample['mocap'] for sample in padded_batch]),\n",
    "            'imu': torch.stack([sample['imu'] for sample in padded_batch])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "\n",
    "# model = SimpleNN(input_size=4*3, hidden_size=8*3, num_layers=2) \n",
    "\n",
    "model = ConvTransformer(\n",
    "    input_dim=12,\n",
    "    transformer_dim=64,\n",
    "    window_size=window_size,\n",
    "    nhead=8,\n",
    "    dim_feedforward=256,\n",
    "    transformer_dropout=0.1,\n",
    "    transformer_activation=\"gelu\",\n",
    "    num_encoder_layers=6,\n",
    "    encode_position=True\n",
    ")\n",
    "\n",
    "# model = BiLSTM(input_size=12, hidden_size=12, num_layers=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "\n",
    "# ⭐ Define loss weights\n",
    "angle_weight = 0.1\n",
    "bone_length_weight = 0.2\n",
    "\n",
    "# Create a dictionary to store metrics\n",
    "metrics = {\n",
    "    'train_loss': [],\n",
    "    'test_loss': [],\n",
    "    'train_mse': [],\n",
    "    'test_mse': [],\n",
    "    'train_angle': [],\n",
    "    'test_angle': [],\n",
    "    'train_bone': [],\n",
    "    'test_bone': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Running epoch [{epoch+1}/{num_epochs}]')\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_mse = 0\n",
    "    epoch_train_angle = 0\n",
    "    epoch_train_bone = 0\n",
    "    \n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        # Move batch data onto device\n",
    "        batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch['imu'])\n",
    "        outputs_reshaped = outputs.view(*batch['mocap'].shape)\n",
    "        \n",
    "        # Calculate different loss components\n",
    "        mse_loss = F.mse_loss(outputs_reshaped, batch['mocap'])\n",
    "        angle_loss = angle_constraint_loss(outputs_reshaped, alpha=angle_weight)\n",
    "        bone_loss = bone_length_consistency_loss(outputs_reshaped, alpha=bone_length_weight)\n",
    "        \n",
    "        # ⭐ Combine losses\n",
    "        total_loss = mse_loss + angle_loss + bone_loss\n",
    "        # total_loss = mse_loss\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate losses\n",
    "        epoch_train_loss += total_loss.item()\n",
    "        epoch_train_mse += mse_loss.item()\n",
    "        epoch_train_angle += angle_loss.item()\n",
    "        epoch_train_bone += bone_loss.item()\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            print(f'Train Step [{i+1}/{len(train_dataloader)}], Total Loss: {total_loss.item():.4f}, '\n",
    "                  f'MSE: {mse_loss.item():.4f}, Angle: {angle_loss.item():.4f}, Bone: {bone_loss.item():.4f}')\n",
    "    \n",
    "    # Average losses for the epoch\n",
    "    epoch_train_loss /= len(train_dataloader)\n",
    "    epoch_train_mse /= len(train_dataloader)\n",
    "    epoch_train_angle /= len(train_dataloader)\n",
    "    epoch_train_bone /= len(train_dataloader)\n",
    "    \n",
    "    # Store metrics\n",
    "    metrics['train_loss'].append(epoch_train_loss)\n",
    "    metrics['train_mse'].append(epoch_train_mse)\n",
    "    metrics['train_angle'].append(epoch_train_angle)\n",
    "    metrics['train_bone'].append(epoch_train_bone)\n",
    "    \n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    epoch_test_loss = 0\n",
    "    epoch_test_mse = 0\n",
    "    epoch_test_angle = 0\n",
    "    epoch_test_bone = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_dataloader):\n",
    "            #Move batch data onto device\n",
    "            batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch['imu'])\n",
    "            outputs_reshaped = outputs.view(*batch['mocap'].shape)\n",
    "            \n",
    "            # Calculate different loss components\n",
    "            mse_loss = F.mse_loss(outputs_reshaped, batch['mocap'])\n",
    "            angle_loss = angle_constraint_loss(outputs_reshaped, alpha=angle_weight)\n",
    "            bone_loss = bone_length_consistency_loss(outputs_reshaped, alpha=bone_length_weight)\n",
    "            \n",
    "            # Combine losses\n",
    "            total_loss = mse_loss + angle_loss + bone_loss\n",
    "            # total_loss = mse_loss\n",
    "            \n",
    "            # Accumulate losses\n",
    "            epoch_test_loss += total_loss.item()\n",
    "            epoch_test_mse += mse_loss.item()\n",
    "            epoch_test_angle += angle_loss.item()\n",
    "            epoch_test_bone += bone_loss.item()\n",
    "            \n",
    "            if (i+1) % 200 == 0:\n",
    "                print(f'Test Step [{i+1}/{len(test_dataloader)}], Total Loss: {total_loss.item():.4f}, '\n",
    "                      f'MSE: {mse_loss.item():.4f}, Angle: {angle_loss.item():.4f}, Bone: {bone_loss.item():.4f}')\n",
    "    \n",
    "    # Average losses for the epoch\n",
    "    epoch_test_loss /= len(test_dataloader)\n",
    "    epoch_test_mse /= len(test_dataloader)\n",
    "    epoch_test_angle /= len(test_dataloader)\n",
    "    epoch_test_bone /= len(test_dataloader)\n",
    "    \n",
    "    # Store metrics\n",
    "    metrics['test_loss'].append(epoch_test_loss)\n",
    "    metrics['test_mse'].append(epoch_test_mse)\n",
    "    metrics['test_angle'].append(epoch_test_angle)\n",
    "    metrics['test_bone'].append(epoch_test_bone)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {epoch_train_loss:.4f}, Test Loss: {epoch_test_loss:.4f}')\n",
    "    \n",
    "    # Save model checkpoint if desired\n",
    "    if epoch % 5 == 4:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': epoch_test_loss,\n",
    "            'metrics': metrics\n",
    "        }, f'checkpoint_epoch_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⭐ Calculate MPJPE (Mean Per Joint Position Error) / MPVE (Mean Per Joint Velocity Error)\n",
    "- Goal: MPJPE < 0.10~0.20 m (10–20cm), MPVE < ~1cm/s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mpjpe(predictions, targets):\n",
    "    \"\"\"\n",
    "    predictions, targets: (B, T, J, 3)\n",
    "    Returns: scalar MPJPE (in meters)\n",
    "    \"\"\"\n",
    "    error = torch.norm(predictions - targets, dim=-1)  # (B, T, J)\n",
    "    return error.mean().item()\n",
    "\n",
    "def compute_mpve(predictions, targets):\n",
    "    \"\"\"\n",
    "    predictions, targets: (B, T, J, 3)\n",
    "    Returns: scalar MPVE (in m/s)\n",
    "    \"\"\"\n",
    "    pred_velocity = predictions[:, 1:, :, :] - predictions[:, :-1, :, :]  # (B, T-1, J, 3)\n",
    "    target_velocity = targets[:, 1:, :, :] - targets[:, :-1, :, :]        # (B, T-1, J, 3)\n",
    "\n",
    "    velocity_error = torch.norm(pred_velocity - target_velocity, dim=-1)  # (B, T-1, J)\n",
    "    return velocity_error.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation loop\n",
    "model.eval()\n",
    "\n",
    "# Initialize accumulators\n",
    "epoch_test_loss = 0\n",
    "epoch_test_mse = 0\n",
    "epoch_test_angle = 0\n",
    "epoch_test_bone = 0\n",
    "epoch_test_mpjpe = 0\n",
    "epoch_test_mpve = 0\n",
    "\n",
    "metrics = {\n",
    "    'train_loss': [],\n",
    "    'test_loss': [],\n",
    "    'train_mse': [],\n",
    "    'test_mse': [],\n",
    "    'train_angle': [],\n",
    "    'test_angle': [],\n",
    "    'train_bone': [],\n",
    "    'test_bone': [],\n",
    "     'test_mpjpe': [],  \n",
    "    'test_mpve': []\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        #Move batch data onto device\n",
    "        batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch['imu'])  # Shape: (B, T*J*3)\n",
    "        outputs_reshaped = outputs.view(*batch['mocap'].shape)  # (B, T, J, 3)\n",
    "\n",
    "        # Loss components\n",
    "        mse_loss = F.mse_loss(outputs_reshaped, batch['mocap'])\n",
    "        angle_loss = angle_constraint_loss(outputs_reshaped, alpha=angle_weight)\n",
    "        bone_loss = bone_length_consistency_loss(outputs_reshaped, alpha=bone_length_weight)\n",
    "        total_loss = mse_loss + angle_loss + bone_loss\n",
    "        # total_loss = mse_loss\n",
    "\n",
    "        # Accumulate losses\n",
    "        epoch_test_loss += total_loss.item()\n",
    "        epoch_test_mse += mse_loss.item()\n",
    "        epoch_test_angle += angle_loss.item()\n",
    "        epoch_test_bone += bone_loss.item()\n",
    "\n",
    "        # ➕ Compute MPJPE and MPVE\n",
    "        epoch_test_mpjpe += compute_mpjpe(outputs_reshaped, batch['mocap'])\n",
    "        epoch_test_mpve += compute_mpve(outputs_reshaped, batch['mocap'])\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Test Step [{i+1}/{len(test_dataloader)}], '\n",
    "                  f'Total Loss: {total_loss.item():.4f}, '\n",
    "                  f'MSE: {mse_loss.item():.4f}, '\n",
    "                  f'Angle: {angle_loss.item():.4f}, '\n",
    "                  f'Bone: {bone_loss.item():.4f}')\n",
    "\n",
    "# Average over all batches\n",
    "epoch_test_loss /= len(test_dataloader)\n",
    "epoch_test_mse /= len(test_dataloader)\n",
    "epoch_test_angle /= len(test_dataloader)\n",
    "epoch_test_bone /= len(test_dataloader)\n",
    "epoch_test_mpjpe /= len(test_dataloader)\n",
    "epoch_test_mpve /= len(test_dataloader)\n",
    "\n",
    "# Store metrics\n",
    "metrics['test_loss'].append(epoch_test_loss)\n",
    "metrics['test_mse'].append(epoch_test_mse)\n",
    "metrics['test_angle'].append(epoch_test_angle)\n",
    "metrics['test_bone'].append(epoch_test_bone)\n",
    "metrics['test_mpjpe'].append(epoch_test_mpjpe)\n",
    "metrics['test_mpve'].append(epoch_test_mpve)\n",
    "\n",
    "# Summary\n",
    "print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "      f'Test Loss: {epoch_test_loss:.4f}, '\n",
    "      f'MSE: {epoch_test_mse:.4f} ',\n",
    "      f'MPJPE: {epoch_test_mpjpe:.4f}, '\n",
    "      f'MPVE: {epoch_test_mpve:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⭐ Evaluate Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after outputs_reshaped is computed\n",
    "mpjpe = compute_mpjpe(outputs_reshaped, batch['mocap'])\n",
    "mpve = compute_mpve(outputs_reshaped, batch['mocap'])\n",
    "\n",
    "epoch_test_mpjpe += mpjpe\n",
    "epoch_test_mpve += mpve\n",
    "\n",
    "print(epoch_test_mpjpe)\n",
    "print(epoch_test_mpve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⭐ Visualize a result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import visualize_model_predictions\n",
    "\n",
    "# Call the visualization function after training\n",
    "visualize_model_predictions(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Skeleton Animation with Ground Truth vs Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "\n",
    "# If pred/gt are torch tensors, convert to numpy\n",
    "pred = outputs_reshaped[0].detach().cpu().numpy()  # shape: (T, 8, 3)\n",
    "gt = batch['mocap'][0].detach().cpu().numpy()      # shape: (T, 8, 3)\n",
    "T = pred.shape[0]\n",
    "\n",
    "# Joint connection pairs (for stick figure)\n",
    "# Each tuple connects 2 joints by index. Adjust as needed.\n",
    "connections = [(0, 1), (1, 2), (2, 3),  # left arm\n",
    "               (4, 5), (5, 6), (6, 7)]  # right arm\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "def update(frame):\n",
    "    ax.cla()  # Clear the previous frame\n",
    "\n",
    "    # Plot predicted joints\n",
    "    pred_joints = pred[frame]\n",
    "    gt_joints = gt[frame]\n",
    "\n",
    "    for i, j in connections:\n",
    "        ax.plot(*zip(pred_joints[i], pred_joints[j]), color='r', linewidth=2, label='Predicted' if i == 0 else \"\")\n",
    "        ax.plot(*zip(gt_joints[i], gt_joints[j]), color='g', linestyle='--', linewidth=2, label='Ground Truth' if i == 0 else \"\")\n",
    "\n",
    "    ax.scatter(pred_joints[:, 0], pred_joints[:, 1], pred_joints[:, 2], color='r')\n",
    "    ax.scatter(gt_joints[:, 0], gt_joints[:, 1], gt_joints[:, 2], color='g', marker='^')\n",
    "\n",
    "    ax.set_xlim([-1, 1])\n",
    "    ax.set_ylim([-1, 1])\n",
    "    ax.set_zlim([-1, 1])\n",
    "    ax.set_title(f'Frame {frame}')\n",
    "    ax.legend(loc='best')\n",
    "    ax.view_init(elev=20, azim=120)  # Adjust view angle\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=T, interval=100)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
