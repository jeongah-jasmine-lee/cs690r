{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff3dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import ConvTransformer, SimpleNN, BiLSTM\n",
    "from losses import angle_constraint_loss, bone_length_consistency_loss\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3c230b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data containing:\n",
      "Array time of shape (596,)\n",
      "Array leftShoulderPosRel of shape (596, 3)\n",
      "Array rightShoulderPosRel of shape (596, 3)\n",
      "Array leftElbowPosRel of shape (596, 3)\n",
      "Array rightElbowPosRel of shape (596, 3)\n",
      "Array leftWristPosRel of shape (596, 3)\n",
      "Array rightWristPosRel of shape (596, 3)\n",
      "Array leftFingerPosRel of shape (596, 3)\n",
      "Array rightFingerPosRel of shape (596, 3)\n",
      "Array accelerationLeftLoc of shape (596, 3)\n",
      "Array accelerationRightLoc of shape (596, 3)\n",
      "Array gyroLeftLoc of shape (596, 3)\n",
      "Array gyroRightLoc of shape (596, 3)\n",
      "Sample rate: 60.0\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob('../data/*.npz')\n",
    "assert len(filenames) > 0, 'No data files found in ./data/'\n",
    "\n",
    "filename = filenames[1]\n",
    "data = np.load(filename)\n",
    "print('Data containing:')\n",
    "[print(f'Array {f} of shape {data[f].shape}') for f in data.files];\n",
    "\n",
    "dt = np.diff(data['time'])\n",
    "SAMPLE_RATE = 1.0 / np.mean(dt)\n",
    "print('Sample rate:', SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fc4efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found subjects: ['s1' 's10' 's2' 's3' 's4' 's5' 's6' 's7' 's8' 's9']\n",
      "Training on subjects: ['s8' 's10' 's5' 's1' 's7' 's2' 's9' 's4' 's3']\n",
      "Testing on subjects: ['s6']\n"
     ]
    }
   ],
   "source": [
    "subjects = np.unique([f.split('_')[-2] for f in filenames])\n",
    "print(f'Found subjects: {subjects}')\n",
    "\n",
    "np.random.seed(42) # For reproducibility\n",
    "permutation = np.random.permutation(len(subjects))\n",
    "train_subjects = subjects[permutation[:-1]]\n",
    "test_subjects = subjects[permutation[-1:]]\n",
    "\n",
    "print(f'Training on subjects: {train_subjects}')\n",
    "print(f'Testing on subjects: {test_subjects}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9052f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch 25 with loss 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick-do/Documents/Projects/CS690R_Project/cs690r/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    longest_sample = max(batch, key=lambda x: len(x['time']))\n",
    "    max_len = len(longest_sample['time']) # max_len\n",
    "    padded_batch = []\n",
    "\n",
    "    for sample in batch:\n",
    "        padding_len = max_len - len(sample['time'])\n",
    "        padded_sample = {}\n",
    "        padded_sample['mocap'] = torch.cat([sample['mocap'],\n",
    "                                            sample['mocap'][-1:].repeat(padding_len,1,1)]) # (max_len, 8, 3)\n",
    "        acc = torch.cat([sample['imu'][:,[0,1]],\n",
    "                         sample['imu'][-1:,[0,1]].repeat(padding_len,1,1)]) # (max_len, 2, 3)\n",
    "        gyro = torch.cat([sample['imu'][:,[2,3]],\n",
    "                          torch.zeros_like(sample['imu'][-1:,[2,3]]).repeat(padding_len,1,1)]) # (max_len, 2, 3)\n",
    "        padded_sample['imu'] = torch.cat([acc, gyro], dim=1) # (max_len, 4, 3)\n",
    "        padded_batch.append(padded_sample)\n",
    "\n",
    "    return {'time': longest_sample['time'],\n",
    "            'mocap': torch.stack([sample['mocap'] for sample in padded_batch]),\n",
    "            'imu': torch.stack([sample['imu'] for sample in padded_batch])}\n",
    "\n",
    "def compute_mpjpe(predictions, targets):\n",
    "    \"\"\"\n",
    "    predictions, targets: (B, T, J, 3)\n",
    "    Returns: scalar MPJPE (in meters)\n",
    "    \"\"\"\n",
    "    error = torch.norm(predictions - targets, dim=-1)  # (B, T, J)\n",
    "    return error.mean().item()\n",
    "\n",
    "def compute_mpve(predictions, targets):\n",
    "    \"\"\"\n",
    "    predictions, targets: (B, T, J, 3)\n",
    "    Returns: scalar MPVE (in m/s)\n",
    "    \"\"\"\n",
    "    pred_velocity = predictions[:, 1:, :, :] - predictions[:, :-1, :, :]  # (B, T-1, J, 3)\n",
    "    target_velocity = targets[:, 1:, :, :] - targets[:, :-1, :, :]        # (B, T-1, J, 3)\n",
    "\n",
    "    velocity_error = torch.norm(pred_velocity - target_velocity, dim=-1)  # (B, T-1, J)\n",
    "    return velocity_error.mean().item()\n",
    "\n",
    "# 1) Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2) Instantiate model with the same hyperparameters you used at train time\n",
    "window_size = 60\n",
    "batch_size = 32\n",
    "\n",
    "### MODEL OPTION 1: Baseline LSTM -------------------------------\n",
    "\n",
    "# model = SimpleNN(input_size=4*3, hidden_size=8*3, num_layers=2) \n",
    "\n",
    "### -------------------------------------------------------------\n",
    "\n",
    "\n",
    "### MODEL OPTION 2: ConvTransformer -----------------------------\n",
    "\n",
    "model = ConvTransformer(\n",
    "    input_dim=12,\n",
    "    transformer_dim=64,\n",
    "    window_size=window_size,\n",
    "    nhead=8,\n",
    "    dim_feedforward=256,\n",
    "    transformer_dropout=0.1,\n",
    "    transformer_activation=\"gelu\",\n",
    "    num_encoder_layers=6,\n",
    "    encode_position=True\n",
    ")\n",
    "\n",
    "###---------------------------------------------------------------\n",
    "\n",
    "\n",
    "### MODEL OPTION 3: Bidirectional LSTM ---------------------------\n",
    "\n",
    "# model = BiLSTM(input_size=12, hidden_size=12, num_layers=2)\n",
    "\n",
    "###---------------------------------------------------------------\n",
    "model.to(device)\n",
    "\n",
    "# 3) Load pretrained weights\n",
    "CHECKPOINT_PATH = \"convtransformer_nopreprocess_withconstraints_batchsize32_winsize60_winshift15/checkpoint_epoch_24.pth\"\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "print(f\"Loaded checkpoint from epoch {checkpoint['epoch']+1} with loss {checkpoint['loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bfb8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "##### PLEASE CHOOSE WINDOW SHIFT OF 1 ######\n",
    "# Call the visualization function after training\n",
    "vis_dataset = IMUDataset([f for f in filenames if any(s == f.split('_')[-2] for s in test_subjects)], \n",
    "                          filter=False, \n",
    "                          window_size=window_size, \n",
    "                          window_shift=1)\n",
    "\n",
    "vis_result_path = 'result_convTrans' # Path of visualization results\n",
    "os.makedirs(vis_result_path, exist_ok=True)\n",
    "\n",
    "visualize_each_file(model, vis_dataset, device, fps=30, save_path=vis_result_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
