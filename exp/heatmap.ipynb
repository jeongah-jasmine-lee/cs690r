{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "from dataset import *\n",
    "from model import *\n",
    "from vis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# ──────────────────────────────────────────────────────────\n",
    "#  Inference + Error-heatmap visualisation for IMU→Skeleton\n",
    "# ──────────────────────────────────────────────────────────\n",
    "import os, glob, numpy as np\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "import os, glob, numpy as np\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "\n",
    "# ───────────────────────── Heat-maps ─────────────────────\n",
    "def plot_joint_error_heatmap(pred, gt, path=None):\n",
    "    errs = np.linalg.norm(pred-gt, axis=-1)    # (T,J)\n",
    "    fig,ax=plt.subplots(figsize=(8,4))\n",
    "    im = ax.imshow(errs.mean(0)[None,:], cmap='Reds', aspect='auto')\n",
    "    ax.set_xlabel('Joint Index'); ax.set_yticks([]); ax.set_title('Mean Joint Errors')\n",
    "    cbar=plt.colorbar(im,ax=ax); cbar.set_label('MPJPE (m)',rotation=270,labelpad=15)\n",
    "    if path: os.makedirs(os.path.dirname(path),exist_ok=True); plt.savefig(path,dpi=300,bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_frame_error_heatmap(pred, gt, path=None):\n",
    "    errs = np.linalg.norm(pred-gt, axis=-1)    # (T,J)\n",
    "    fig,ax=plt.subplots(figsize=(8,4))\n",
    "    im = ax.imshow(errs.mean(1)[:,None].T,cmap='Blues',aspect='auto')\n",
    "    ax.set_xticks(np.linspace(0,len(errs)-1,10,dtype=int))\n",
    "    ax.set_xlabel('Frame Index'); ax.set_ylabel('Error'); ax.set_title('Mean Frame Errors')\n",
    "    cbar=plt.colorbar(im,ax=ax); cbar.set_label('MPJPE (m)',rotation=270,labelpad=15)\n",
    "    if path: os.makedirs(os.path.dirname(path),exist_ok=True); plt.savefig(path,dpi=300,bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 10000\n",
    "\n",
    "def visualize_skeleton_comparison(ground_truth, predictions, frame_idx=0, title='Skeleton Comparison'):\n",
    "    \"\"\"\n",
    "    Visualize ground truth vs predicted skeletons\n",
    "    \n",
    "    Args:\n",
    "        ground_truth: Tensor of shape (seq_len, 8, 3) or array-like\n",
    "        predictions: Tensor of shape (seq_len, 8, 3) or array-like\n",
    "        frame_idx: Index of the frame to visualize\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    # Convert to numpy if tensors\n",
    "    if isinstance(ground_truth, torch.Tensor):\n",
    "        ground_truth = ground_truth.detach().cpu().numpy()\n",
    "    if isinstance(predictions, torch.Tensor):\n",
    "        predictions = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    # Extract specific frame\n",
    "    gt_frame = ground_truth[frame_idx]  # Shape: (8, 3)\n",
    "    pred_frame = predictions[frame_idx]  # Shape: (8, 3)\n",
    "    \n",
    "    # Define the connections for visualization (joint indices)\n",
    "    left_arm_connections = [(0, 1), (1, 2), (2, 3)]  # Shoulder -> Elbow -> Wrist -> Finger\n",
    "    right_arm_connections = [(4, 5), (5, 6), (6, 7)]  # Shoulder -> Elbow -> Wrist -> Finger\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    # Setup 3 views: front (XZ), side (YZ), top (XY)\n",
    "    views = [(0, 2, 'Front View (XZ)'), (1, 2, 'Side View (YZ)'), (0, 1, 'Top View (XY)')]\n",
    "    \n",
    "    for i, (dim1, dim2, view_title) in enumerate(views):\n",
    "        ax = fig.add_subplot(1, 3, i+1)\n",
    "        ax.set_title(f\"{view_title}\")\n",
    "        \n",
    "        # Plot ground truth left arm\n",
    "        for start_idx, end_idx in left_arm_connections:\n",
    "            ax.plot([gt_frame[start_idx, dim1], gt_frame[end_idx, dim1]], \n",
    "                    [gt_frame[start_idx, dim2], gt_frame[end_idx, dim2]], \n",
    "                    'b-', linewidth=3, alpha=0.7)\n",
    "        \n",
    "        # Plot ground truth right arm\n",
    "        for start_idx, end_idx in right_arm_connections:\n",
    "            ax.plot([gt_frame[start_idx, dim1], gt_frame[end_idx, dim1]], \n",
    "                    [gt_frame[start_idx, dim2], gt_frame[end_idx, dim2]], \n",
    "                    'g-', linewidth=3, alpha=0.7)\n",
    "        \n",
    "        # Plot predicted left arm\n",
    "        for start_idx, end_idx in left_arm_connections:\n",
    "            ax.plot([pred_frame[start_idx, dim1], pred_frame[end_idx, dim1]], \n",
    "                    [pred_frame[start_idx, dim2], pred_frame[end_idx, dim2]], \n",
    "                    'b--', linewidth=2)\n",
    "        \n",
    "        # Plot predicted right arm\n",
    "        for start_idx, end_idx in right_arm_connections:\n",
    "            ax.plot([pred_frame[start_idx, dim1], pred_frame[end_idx, dim1]], \n",
    "                    [pred_frame[start_idx, dim2], pred_frame[end_idx, dim2]], \n",
    "                    'g--', linewidth=2)\n",
    "        \n",
    "        # Plot joints\n",
    "        ax.scatter(gt_frame[:4, dim1], gt_frame[:4, dim2], c='blue', s=50, label='GT Left Arm')\n",
    "        ax.scatter(gt_frame[4:, dim1], gt_frame[4:, dim2], c='green', s=50, label='GT Right Arm')\n",
    "        ax.scatter(pred_frame[:4, dim1], pred_frame[:4, dim2], c='cyan', s=30, label='Pred Left Arm')\n",
    "        ax.scatter(pred_frame[4:, dim1], pred_frame[4:, dim2], c='lime', s=30, label='Pred Right Arm')\n",
    "        \n",
    "        # Set the aspect ratio to be equal\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "        # Set labels\n",
    "        ax.set_xlabel(f\"Dimension {dim1}\")\n",
    "        ax.set_ylabel(f\"Dimension {dim2}\")\n",
    "        \n",
    "        # Add legend\n",
    "        if i == 0:\n",
    "            ax.legend(loc='upper left')  # or 'best' or 'lower left', etc.\n",
    "\n",
    "        \n",
    "        # Add grid\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def create_skeleton_animation(ground_truth, predictions, save_path=None, fps=30, duration=None):\n",
    "    \"\"\"\n",
    "    Create animation comparing ground truth and predicted skeletons\n",
    "    \n",
    "    Args:\n",
    "        ground_truth: Tensor of shape (seq_len, 8, 3) or array-like\n",
    "        predictions: Tensor of shape (seq_len, 8, 3) or array-like\n",
    "        save_path: Path to save the animation. If None, the animation is not saved\n",
    "        fps: Frames per second\n",
    "        duration: Duration of the animation in seconds. If None, all frames are used\n",
    "    \n",
    "    Returns:\n",
    "        Animation object that can be displayed in a notebook\n",
    "    \"\"\"\n",
    "    # Convert to numpy if tensors\n",
    "    if isinstance(ground_truth, torch.Tensor):\n",
    "        ground_truth = ground_truth.detach().cpu().numpy()\n",
    "    if isinstance(predictions, torch.Tensor):\n",
    "        predictions = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    # Define the connections for visualization\n",
    "    left_arm_connections = [(0, 1), (1, 2), (2, 3)]  # Shoulder -> Elbow -> Wrist -> Finger\n",
    "    right_arm_connections = [(4, 5), (5, 6), (6, 7)]  # Shoulder -> Elbow -> Wrist -> Finger\n",
    "    \n",
    "    # Calculate the total number of frames to display\n",
    "    total_frames = len(ground_truth)\n",
    "    if duration is not None:\n",
    "        total_frames = min(total_frames, int(duration * fps))\n",
    "    \n",
    "    # Create figure and axes\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    axes = [fig.add_subplot(1, 3, i+1) for i in range(3)]\n",
    "    \n",
    "    # Set view titles\n",
    "    view_titles = ['Front View (XZ)', 'Side View (YZ)', 'Top View (XY)']\n",
    "    views = [(0, 2), (1, 2), (0, 1)]  # Dimensions to plot for each view\n",
    "    \n",
    "    for ax, title in zip(axes, view_titles):\n",
    "        ax.set_title(title)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Set axis limits based on the data range with some padding\n",
    "    pad = 0.1\n",
    "    min_vals = np.min(np.concatenate([ground_truth, predictions]), axis=(0, 1))\n",
    "    max_vals = np.max(np.concatenate([ground_truth, predictions]), axis=(0, 1))\n",
    "    range_vals = max_vals - min_vals\n",
    "    min_vals -= range_vals * pad\n",
    "    max_vals += range_vals * pad\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        dim1, dim2 = views[i]\n",
    "        ax.set_xlim(min_vals[dim1], max_vals[dim1])\n",
    "        ax.set_ylim(min_vals[dim2], max_vals[dim2])\n",
    "    \n",
    "    # Initialize lines and points for ground truth\n",
    "    gt_left_lines = [[ax.plot([], [], 'b-', linewidth=3, alpha=0.7)[0] for _ in left_arm_connections] for ax in axes]\n",
    "    gt_right_lines = [[ax.plot([], [], 'g-', linewidth=3, alpha=0.7)[0] for _ in right_arm_connections] for ax in axes]\n",
    "    gt_left_points = [ax.scatter([], [], c='blue', s=50, label='GT Left Arm') for ax in axes]\n",
    "    gt_right_points = [ax.scatter([], [], c='green', s=50, label='GT Right Arm') for ax in axes]\n",
    "    \n",
    "    # Initialize lines and points for predictions\n",
    "    pred_left_lines = [[ax.plot([], [], 'b--', linewidth=2)[0] for _ in left_arm_connections] for ax in axes]\n",
    "    pred_right_lines = [[ax.plot([], [], 'g--', linewidth=2)[0] for _ in right_arm_connections] for ax in axes]\n",
    "    pred_left_points = [ax.scatter([], [], c='cyan', s=30, label='Pred Left Arm') for ax in axes]\n",
    "    pred_right_points = [ax.scatter([], [], c='lime', s=30, label='Pred Right Arm') for ax in axes]\n",
    "    \n",
    "    # Add legend to the first axis\n",
    "    axes[0].legend(loc='upper right')\n",
    "    \n",
    "    # Frame counter text\n",
    "    frame_text = fig.text(0.5, 0.95, '', ha='center')\n",
    "    \n",
    "    def init():\n",
    "        \"\"\"Initialize the animation\"\"\"\n",
    "        for ax_gt_left_lines in gt_left_lines:\n",
    "            for line in ax_gt_left_lines:\n",
    "                line.set_data([], [])\n",
    "        \n",
    "        for ax_gt_right_lines in gt_right_lines:\n",
    "            for line in ax_gt_right_lines:\n",
    "                line.set_data([], [])\n",
    "        \n",
    "        for ax_pred_left_lines in pred_left_lines:\n",
    "            for line in ax_pred_left_lines:\n",
    "                line.set_data([], [])\n",
    "        \n",
    "        for ax_pred_right_lines in pred_right_lines:\n",
    "            for line in ax_pred_right_lines:\n",
    "                line.set_data([], [])\n",
    "        \n",
    "        for point in gt_left_points + gt_right_points + pred_left_points + pred_right_points:\n",
    "            point.set_offsets(np.empty((0, 2)))\n",
    "        \n",
    "        frame_text.set_text('')\n",
    "        \n",
    "        return (sum(gt_left_lines, []) + sum(gt_right_lines, []) + \n",
    "                sum(pred_left_lines, []) + sum(pred_right_lines, []) + \n",
    "                gt_left_points + gt_right_points + pred_left_points + pred_right_points + \n",
    "                [frame_text])\n",
    "    \n",
    "    def update(frame_idx):\n",
    "        \"\"\"Update the animation for a specific frame\"\"\"\n",
    "        gt_frame = ground_truth[frame_idx]\n",
    "        pred_frame = predictions[frame_idx]\n",
    "        \n",
    "        # Update ground truth lines and points\n",
    "        for i, ax in enumerate(axes):\n",
    "            dim1, dim2 = views[i]\n",
    "            \n",
    "            # Update ground truth left arm\n",
    "            for j, (start_idx, end_idx) in enumerate(left_arm_connections):\n",
    "                gt_left_lines[i][j].set_data(\n",
    "                    [gt_frame[start_idx, dim1], gt_frame[end_idx, dim1]],\n",
    "                    [gt_frame[start_idx, dim2], gt_frame[end_idx, dim2]]\n",
    "                )\n",
    "            \n",
    "            # Update ground truth right arm\n",
    "            for j, (start_idx, end_idx) in enumerate(right_arm_connections):\n",
    "                gt_right_lines[i][j].set_data(\n",
    "                    [gt_frame[start_idx, dim1], gt_frame[end_idx, dim1]],\n",
    "                    [gt_frame[start_idx, dim2], gt_frame[end_idx, dim2]]\n",
    "                )\n",
    "            \n",
    "            # Update predicted left arm\n",
    "            for j, (start_idx, end_idx) in enumerate(left_arm_connections):\n",
    "                pred_left_lines[i][j].set_data(\n",
    "                    [pred_frame[start_idx, dim1], pred_frame[end_idx, dim1]],\n",
    "                    [pred_frame[start_idx, dim2], pred_frame[end_idx, dim2]]\n",
    "                )\n",
    "            \n",
    "            # Update predicted right arm\n",
    "            for j, (start_idx, end_idx) in enumerate(right_arm_connections):\n",
    "                pred_right_lines[i][j].set_data(\n",
    "                    [pred_frame[start_idx, dim1], pred_frame[end_idx, dim1]],\n",
    "                    [pred_frame[start_idx, dim2], pred_frame[end_idx, dim2]]\n",
    "                )\n",
    "            \n",
    "            # Update points\n",
    "            gt_left_points[i].set_offsets(gt_frame[:4, [dim1, dim2]])\n",
    "            gt_right_points[i].set_offsets(gt_frame[4:, [dim1, dim2]])\n",
    "            pred_left_points[i].set_offsets(pred_frame[:4, [dim1, dim2]])\n",
    "            pred_right_points[i].set_offsets(pred_frame[4:, [dim1, dim2]])\n",
    "        \n",
    "        # Update frame counter\n",
    "        frame_text.set_text(f'Frame: {frame_idx+1}/{total_frames}')\n",
    "        \n",
    "        return (sum(gt_left_lines, []) + sum(gt_right_lines, []) + \n",
    "                sum(pred_left_lines, []) + sum(pred_right_lines, []) + \n",
    "                gt_left_points + gt_right_points + pred_left_points + pred_right_points + \n",
    "                [frame_text])\n",
    "    \n",
    "    # Create the animation\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig, update, frames=total_frames, init_func=init, \n",
    "        blit=True, interval=1000/fps, repeat=True\n",
    "    )\n",
    "    \n",
    "    # Save animation if a path is provided\n",
    "    if save_path is not None:\n",
    "        # Save .mp4\n",
    "        writer = animation.FFMpegWriter(fps=fps)\n",
    "        ani.save(save_path + '.mp4', writer=writer)\n",
    "        \n",
    "        # Save .gif\n",
    "        ani.save(save_path + '.gif', writer='pillow')\n",
    "        \n",
    "        print(f\"Animation saved to {save_path}.mp4 and {save_path}.gif\")\n",
    "    \n",
    "    plt.close()\n",
    "    return ani\n",
    "\n",
    "def visualize_model_predictions(model, test_dataloader, num_samples=1, save_animations=False):\n",
    "    \"\"\"\n",
    "    Visualize model predictions for a few test samples in a controlled manner.\n",
    "    \n",
    "    This updated version shows:\n",
    "      - Only one sample per batch (as set by num_samples).\n",
    "      - Two static frames: the first and the last frame.\n",
    "      - One animation per sample showing the full sequence.\n",
    "    \n",
    "    For each sample, the function produces:\n",
    "      1. Two static visualization figures with three subplots each (Front View, Side View, and Top View),\n",
    "         comparing the ground truth and predicted skeletons.\n",
    "      2. An animation that displays the entire motion sequence for that sample.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Process only the first batch to reduce computation\n",
    "        for i, batch in enumerate(test_dataloader):\n",
    "            # Run the model on the input IMU data and reshape prediction to match mocap data shape\n",
    "            outputs = model(batch['imu'])\n",
    "            outputs_reshaped = outputs.view(*batch['mocap'].shape)\n",
    "            \n",
    "            # For the static visualization and animation, process only the first 'num_samples'\n",
    "            for j in range(min(num_samples, outputs_reshaped.size(0))):\n",
    "                # Select two key frames: the first frame and the last frame\n",
    "                frame_indices = [0, outputs_reshaped.size(1)-1]\n",
    "                for frame_idx in frame_indices:\n",
    "                    # Visualize static comparison for the selected frames\n",
    "                    fig = visualize_skeleton_comparison(\n",
    "                        batch['mocap'][j], outputs_reshaped[j], \n",
    "                        frame_idx=frame_idx, \n",
    "                        title=f'Sample {j+1}, Frame {frame_idx}'\n",
    "                    )\n",
    "                    # Save figure if needed, or display it\n",
    "                    print(\"Saved figure for sample\", j+1, \"at frame\", frame_idx)\n",
    "                    plt.savefig(f'./result/skeleton_comparison_sample_{j+1}_frame_{frame_idx}.png')\n",
    "                    plt.close(fig)\n",
    "                \n",
    "                # Create an animation for the full motion sequence of this sample.\n",
    "                # The animation uses a specified frame rate (fps) and shows all frames.\n",
    "                ani = create_skeleton_animation(\n",
    "                    batch['mocap'][j], outputs_reshaped[j],\n",
    "                    save_path=f'./result/{model.__class__.__name__}_sample{j+1}_anim',\n",
    "                    fps=30\n",
    "                )\n",
    "\n",
    "                # If you are using a Jupyter Notebook, you can display the animation using:\n",
    "                from IPython.display import HTML\n",
    "                display(HTML(ani.to_jshtml()))\n",
    "            \n",
    "            # Process only the first batch to avoid visualizing too much data\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure for sample 1 at frame 0\n",
      "Saved figure for sample 1 at frame 59\n"
     ]
    }
   ],
   "source": [
    "# ───────────────────────── Main ──────────────────────────\n",
    "def main():\n",
    "    import glob\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    # -------- data --------\n",
    "    npz_dir   = '../data'                     # TODO: update if needed\n",
    "    fnames    = glob.glob(f'{npz_dir}/*.npz')\n",
    "    assert fnames, f'No .npz files in {npz_dir}'\n",
    "    \n",
    "    subjects  = np.unique([f.split('_')[-2] for f in fnames])\n",
    "    np.random.seed(42)\n",
    "    perm      = np.random.permutation(len(subjects))\n",
    "    test_sub  = subjects[perm[-1:]]\n",
    "    test_files = [f for f in fnames if f.split('_')[-2] in test_sub]\n",
    "\n",
    "    # ========== Sliding-window dataset ========== \n",
    "    #test_dataset    = CustomDataset(test_files)\n",
    "    #test_dataloader = DataLoader(test_dataset, batch_size=10, collate_fn=collate_fn)\n",
    "\n",
    "    window_size = 60\n",
    "    window_shift = 15\n",
    "    '''\n",
    "    test_dataset = IMUDataset([f for f in fnames if any(s == f.split('_')[-2] for s in test_sub)], \n",
    "                            filter=False, \n",
    "                            window_size=window_size, \n",
    "                            window_shift=window_shift)\n",
    "    test_dataloader = IMUDataset([f for f in fnames if any(s == f.split('_')[-2] for s in test_files)], \n",
    "                            filter=False, \n",
    "                            window_size=window_size, \n",
    "                            window_shift=window_shift)\n",
    "    '''\n",
    "    test_dataset = IMUDataset(\n",
    "        test_files,\n",
    "        filter=False,\n",
    "        window_size=window_size,\n",
    "        window_shift=window_shift\n",
    "    )\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=10,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "\n",
    "    # -------- model & ckpt --------\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # --------- [1] BiLSTM -----------------\n",
    "    #model = SimpleNN().to(device)\n",
    "    model = BiLSTM(input_size=12, hidden_size=12, num_layers=2).to(device)\n",
    "    \n",
    "    # --------- [2] Transformer -----------------\n",
    "    '''\n",
    "    model = TransformerEncoderModel(\n",
    "        input_size=12,\n",
    "        d_model=64,\n",
    "        nhead=8,\n",
    "        num_layers=2,\n",
    "        dim_feedforward=256,\n",
    "        dropout=0.1\n",
    "    )\n",
    "    '''\n",
    "    # --------- [3] ConvTransformer -----------------\n",
    "    '''\n",
    "    model = ConvTransformer(\n",
    "         input_dim=12,\n",
    "         transformer_dim=64,\n",
    "         window_size=60,\n",
    "         nhead=8,\n",
    "         dim_feedforward=256,\n",
    "         transformer_dropout=0.1,\n",
    "         transformer_activation=\"gelu\",\n",
    "         num_encoder_layers=6,\n",
    "         encode_position=True\n",
    "    ).to(device)\n",
    "    '''\n",
    "    ckpt   = '../models/final/2_lstm_nopreprocess_withconstraints_batchsize32_winsize60_winshift15/checkpoint_epoch_24.pth'  \n",
    "    # TODO: checkpoint path\n",
    "    #model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "    checkpoint = torch.load(ckpt, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # -------- inference on one batch --------\n",
    "    try:\n",
    "        batch = next(iter(test_dataloader))\n",
    "    except StopIteration:\n",
    "        raise RuntimeError(\"test_dataloader is empty — no data loaded.\")\n",
    "    \n",
    "    imu_in  = batch['imu'].to(device)         # (B,T,4,3)\n",
    "    gt_full = batch['mocap']                  # (B,T,8,3) still on CPU\n",
    "    convtransformer = False\n",
    "    with torch.no_grad():\n",
    "        if not convtransformer:\n",
    "            out = model(imu_in).cpu()             # (B, T, 24)\n",
    "            pred_full = out.view(out.size(0), out.size(1), 8, 3)  # (B, T, 8, 3)batch_size, flat = out.shape\n",
    "\n",
    "        if convtransformer:\n",
    "            out = model(imu_in).cpu()  \n",
    "            batch_size, flat = out.shape\n",
    "            num_joints, coords = 8, 3\n",
    "            time_steps = flat // (num_joints * coords)\n",
    "            pred_full = out.view(batch_size, time_steps, num_joints, coords)\n",
    "\n",
    "    # -------- visualize one sample --------\n",
    "    pred = pred_full[0].numpy()               # (T,8,3)\n",
    "    gt   = gt_full[0].numpy()\n",
    "    #plot_joint_error_heatmap(pred, gt, './result/joint_error_heatmap.png')\n",
    "    #plot_frame_error_heatmap(pred, gt, './result/frame_error_heatmap.png')\n",
    "    #print('✓ Heat-maps saved in ./result/')\n",
    "\n",
    "    # -------- visualize all predictions with custom function --------\n",
    "    import os\n",
    "    os.makedirs('./result', exist_ok=True)\n",
    "    visualize_model_predictions(model, test_dataloader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs690r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
